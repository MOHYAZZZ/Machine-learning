{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbours "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _*The code below is my implementation of KNN. I will run it on both datasets(Iris and ionosphere) and compute the accuracy. With K values 1, 3 and 5 to find the best K value, between these 3 values.*_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNearestNeighbour:\n",
    "    # K number of Neighbours\n",
    "    # We can change the value of K for example we can have K = 1 or K = 3 or K = 5 and so on.\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "        \n",
    "    # Same as the fit fucntion in scikit-learn\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "    # An important function in our algroithm that calculates the distance between points in the dataset\n",
    "    def euclidean_dist(self, x1,x2):\n",
    "        dif_between_points = x1-x2 \n",
    "        dif_sqaured = dif_between_points**2\n",
    "        dist = np.sqrt(np.sum(dif_sqaured))\n",
    "        return dist\n",
    "    \n",
    "    # This fucntion populates an array with all the Eculidiean distances which will be sorted later\n",
    "    def populate(self, X_train, X, i):\n",
    "        distances = []\n",
    "        for j in self.X_train:\n",
    "            distance = self.euclidean_dist(j, X[i])\n",
    "            distances.append(distance)\n",
    "        \n",
    "        return distances\n",
    "                \n",
    "    \n",
    "    def neighbor_counter(self, k_neighbour):\n",
    "        count_dict = {}\n",
    "        for label in k_neighbour:\n",
    "            if self.y_train[label] in count_dict:\n",
    "                count_dict[self.y_train[label]] += 1\n",
    "            else:\n",
    "                count_dict[self.y_train[label]] = 1\n",
    "        return count_dict\n",
    "    \n",
    "    # The other important function in this class that predicts the lable for the given X\n",
    "    def pred(self, X):\n",
    "        predictions = []\n",
    "        \n",
    "        for i in range(len(X)):\n",
    "            euclidean_distances = self.populate(self.X_train, X, i)\n",
    "                \n",
    "            # Sorts the distances(ascending order) & only keeps the specidifed K Neighbours\n",
    "            k_neighbour = np.array(euclidean_distances).argsort()[: self.k]\n",
    "            \n",
    "            count = self.neighbor_counter(k_neighbour)      \n",
    "            predictions.append(max(count, key = count.get))\n",
    "            \n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "from sklearn.model_selection import train_test_split\n",
    "ionosphere = np.genfromtxt(\"ionosphere.txt\", delimiter=\",\") #importing the dataset with txt format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris['data'],\n",
    "iris['target'], random_state=2111) #random state in Bday format DDMM given in assignment sheet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K = 1\n",
    "### _This means the model made the correct prediction for 92% of the irises in the test set._\n",
    "\n",
    "### Test error rate is **1 - Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy for k = 1 is 0.9210526315789473\n",
      "Test error rate for k = 1 is 0.079\n"
     ]
    }
   ],
   "source": [
    "KNN = KNearestNeighbour(k = 1)\n",
    "KNN.fit(X_train, y_train)\n",
    "predict = KNN.pred(X_test)\n",
    "y_pred = KNN.pred(X_test)\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "\n",
    "print(\"Test set accuracy for k = 1 is \" + str(accuracy))\n",
    "test_err_rate = 1 - accuracy\n",
    "# Rounded up by 3 decimal points\n",
    "print(\"Test error rate for k = 1 is \" + str(round(test_err_rate, 3)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K = 3\n",
    "### _This means the model made the correct prediction for 94% of the irises in the test set._\n",
    "\n",
    "### Test error rate is **1 - Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy for k = 3 is 0.9473684210526315\n",
      "Test error rate for k = 3 is 0.053\n"
     ]
    }
   ],
   "source": [
    "KNN = KNearestNeighbour(k = 3)\n",
    "KNN.fit(X_train, y_train)\n",
    "predict = KNN.pred(X_test)\n",
    "y_pred = KNN.pred(X_test)\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "\n",
    "print(\"Test set accuracy for k = 3 is \" + str(accuracy))\n",
    "test_err_rate = 1 - accuracy\n",
    "print(\"Test error rate for k = 3 is \" + str(round(test_err_rate, 3)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K = 5\n",
    "### _This means the model made the correct prediction for 94% of the irises in the test set._\n",
    "\n",
    "### Test error rate is **1 - Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy for k = 5 is 0.9473684210526315\n",
      "Test error rate for k = 5 is 0.053\n"
     ]
    }
   ],
   "source": [
    "KNN = KNearestNeighbour(k = 5)\n",
    "KNN.fit(X_train, y_train)\n",
    "predict = KNN.pred(X_test)\n",
    "y_pred = KNN.pred(X_test)\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "\n",
    "print(\"Test set accuracy for k = 5 is \" + str(accuracy))\n",
    "test_err_rate = 1 - accuracy\n",
    "print(\"Test error rate for k = 5 is \" + str(round(test_err_rate, 3)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important infomration from the cells above:\n",
    "#### _K values 3 and 5 are the best since they have the lowest error rate_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the predicted labels for all test samples and comparing them with the true labels for the test samples:\n",
    "\n",
    "#### K = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 1 True label: 1\n",
      "Predicted: 2 True label: 2\n",
      "Predicted: 0 True label: 0\n",
      "Predicted: 0 True label: 0\n",
      "Predicted: 0 True label: 0\n",
      "Predicted: 0 True label: 0\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 2 True label: 2\n",
      "Predicted: 2 True label: 1\n",
      "Predicted: 2 True label: 2\n",
      "Predicted: 0 True label: 0\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 0 True label: 0\n",
      "Predicted: 0 True label: 0\n",
      "Predicted: 2 True label: 2\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 0 True label: 0\n",
      "Predicted: 0 True label: 0\n",
      "Predicted: 2 True label: 2\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 0 True label: 0\n",
      "Predicted: 0 True label: 0\n",
      "Predicted: 2 True label: 2\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 2 True label: 1\n",
      "Predicted: 0 True label: 0\n",
      "Predicted: 0 True label: 0\n",
      "Predicted: 0 True label: 0\n",
      "Predicted: 2 True label: 2\n",
      "Predicted: 0 True label: 0\n",
      "Predicted: 2 True label: 2\n",
      "Predicted: 2 True label: 2\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 2 True label: 2\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 0 True label: 0\n"
     ]
    }
   ],
   "source": [
    "# not needed according to assignment sheet but useful for testing and actually seeing some data.\n",
    "for i in range(len(predict)):\n",
    "    print(\"Predicted: \" + str(predict[i]) + \" True label: \" + str(y_test[i]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.genfromtxt(\"ionosphere.txt\", delimiter=\",\",usecols=np.arange(34))\n",
    "y = np.genfromtxt(\"ionosphere.txt\", delimiter=\",\",usecols=34, dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2102)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K = 1\n",
    "### _This means the model made the correct prediction 89% of the time._\n",
    "\n",
    "### Test error rate is **1 - Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy for k = 1 is 0.8977272727272727\n",
      "Test error rate for k = 1 is 0.102\n"
     ]
    }
   ],
   "source": [
    "KNN = KNearestNeighbour(k = 1)\n",
    "KNN.fit(X_train, y_train)\n",
    "predict = KNN.pred(X_test)\n",
    "y_pred = KNN.pred(X_test)\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "\n",
    "print(\"Test set accuracy for k = 1 is \" + str(accuracy))\n",
    "test_err_rate = 1 - accuracy\n",
    "print(\"Test error rate for k = 1 is \" + str(round(test_err_rate, 3)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K = 3\n",
    "### _This means the model made the correct prediction 90% of the time._\n",
    "\n",
    "### Test error rate is **1 - Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy for k = 3 is 0.9090909090909091\n",
      "Test error rate for k = 3 is 0.091\n"
     ]
    }
   ],
   "source": [
    "KNN = KNearestNeighbour(k = 3)\n",
    "KNN.fit(X_train, y_train)\n",
    "predict = KNN.pred(X_test)\n",
    "y_pred = KNN.pred(X_test)\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "\n",
    "print(\"Test set accuracy for k = 3 is \" + str(accuracy))\n",
    "test_err_rate = 1 - accuracy\n",
    "print(\"Test error rate for k = 3 is \" + str(round(test_err_rate, 3)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K = 5\n",
    "### _This means the model made the correct prediction 87% of the time._\n",
    "\n",
    "### Test error rate is **1 - Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy for k = 5 is 0.875\n",
      "Test error rate for k = 5 is 0.125\n"
     ]
    }
   ],
   "source": [
    "KNN = KNearestNeighbour(k = 5)\n",
    "KNN.fit(X_train, y_train)\n",
    "predict = KNN.pred(X_test)\n",
    "y_pred = KNN.pred(X_test)\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "\n",
    "print(\"Test set accuracy for k = 5 is \" + str(accuracy))\n",
    "test_err_rate = 1 - accuracy\n",
    "print(\"Test error rate for k = 5 is \" + str(round(test_err_rate, 3)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _K value 3 is our best K because it has the lowest error rate, in other words, the highest accuracy._"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the predicted labels for all test samples and comparing them with the true labels for the test samples:\n",
    "\n",
    "#### K = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: -1 True label: -1\n",
      "Predicted: 1 True label: -1\n",
      "Predicted: 1 True label: -1\n",
      "Predicted: -1 True label: -1\n",
      "Predicted: 1 True label: -1\n",
      "Predicted: -1 True label: -1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: -1 True label: -1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: -1 True label: -1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: -1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: -1 True label: -1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: -1 True label: -1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: -1 True label: -1\n",
      "Predicted: -1 True label: -1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: -1\n",
      "Predicted: -1 True label: -1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: -1 True label: -1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: -1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: -1 True label: -1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: -1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: -1\n",
      "Predicted: 1 True label: -1\n",
      "Predicted: 1 True label: -1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: -1 True label: -1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: -1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: -1 True label: -1\n",
      "Predicted: -1 True label: -1\n",
      "Predicted: -1 True label: -1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: 1\n",
      "Predicted: 1 True label: 1\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(predict)):\n",
    "    print(\"Predicted: \" + str(predict[i]) + \" True label: \" + str(y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
